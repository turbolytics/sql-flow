tables:
  sql:
    - name: agg_cities_count
      sql: |
        CREATE TABLE agg_cities_count (
          bucket TIMESTAMPTZ,
          city VARCHAR,
          count INT 
        );
        CREATE UNIQUE INDEX daily_cities_count_idx ON agg_cities_count (bucket, city);

      manager:
        tumbling_window:
          collect_closed_windows_sql: |
            SELECT 
              strftime(date_trunc('hour', bucket), '%Y-%m-%dT%H:%M:%S') AS bucket,
              city,
              count
            FROM agg_cities_count
            WHERE bucket AT TIME ZONE 'utc' < (now()::timestamptz AT TIME ZONE 'UTC' - INTERVAL '60' SECOND) 
            ORDER BY city

          delete_closed_windows_sql: |
            DELETE FROM agg_cities_count 
            WHERE bucket AT TIME ZONE 'utc' < (now()::timestamptz AT TIME ZONE 'UTC' - INTERVAL '60' SECOND)
          
        sink:
          type: kafka
          kafka:
            brokers: [{{ kafka_brokers|default('localhost:9092') }}]
            topic: output-tumbling-window-1

pipeline:
  batch_size: 1000

  source:
    type: kafka
    kafka:
      brokers: [{{ kafka_brokers|default('localhost:9092') }}]
      group_id: test
      auto_offset_reset: earliest
      topics:
        - "{{ topic|default('tumbling-window') }}"

  handler:
    type: 'handlers.InferredMemBatch'
    sql: |
      INSERT INTO agg_cities_count
      BY NAME
      SELECT 
        date_trunc('hour', CAST(timestamp as TIMESTAMP)) as bucket,
        properties.city as city,
        count(*) as count
      FROM batch
      GROUP BY 
        bucket, city
      ON CONFLICT (bucket, city) 
      DO UPDATE SET count = count + EXCLUDED.count

  sink:
    type: noop